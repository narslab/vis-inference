{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c64f398-0c16-44ac-8868-ff7c26450902",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image # used for loading images\n",
    "import numpy as np\n",
    "import csv\n",
    "import natsort\n",
    "from natsort import natsorted\n",
    "import os # used for navigating to image path\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import sys\n",
    "sys.path.append(\"../python/\")\n",
    "from helpers import *\n",
    "import time\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaf31cac-2b8d-4c71-88e0-53dd00609adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELED_IMAGES_DIR = '../../data/tidy/labeled-images/'\n",
    "PROCESSED_IMAGES_DIR = '../../data/tidy/preprocessed-images/'\n",
    "INDEX_DIR = '../../results/conflict-detection/index-tidy/'\n",
    "INDEX_LABELS = INDEX_DIR + 'preprocessed_index.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "207ffcdc-3719-42c2-aecb-567c6f808aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEncoding(image_file_name):\n",
    "    \"\"\"Returns binary encoding for each image.\n",
    "    \"\"\"\n",
    "    word_label = image_file_name.split('_')[0]\n",
    "    if word_label == 'c': \n",
    "        return 1\n",
    "    elif word_label == 'n': \n",
    "        return 0\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76fa2d28-6d73-4b9f-952c-0c5bf8887ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processImageData(seed_value=10, test_set_size=0.2, save_image_binary_files=True):\n",
    "    \"\"\"Processes labeled images into train/test numpy arrays based on a specified augmentation technique: fliplr (horizontal flipping) or occlusion\"\"\"\n",
    "    csv_col_index = ['labeled_image', 'preprocessed_index']\n",
    "    preprocessed_image_dict = {}\n",
    "    data_train = []\n",
    "    data_test = []\n",
    "    data_validation = []\n",
    "    image_list = os.listdir(LABELED_IMAGES_DIR)\n",
    "    train_test_ratio = 1-test_set_size\n",
    "    val_ratio = (test_set_size/train_test_ratio)\n",
    "    val_set_size = val_ratio*train_test_ratio\n",
    "    print(\"Train set size: {tr}%\\n test set size: {te}%\\n validation set size: {val}%\".format(\n",
    "        tr=int((1-(test_set_size+val_set_size))*100),\n",
    "        te=int(test_set_size*100),\n",
    "        val=int(val_set_size*100))\n",
    "         )\n",
    "    random.seed(seed_value) #seed for repeatability\n",
    "    image_list_train, image_list_test =  train_test_split(image_list, test_size = test_set_size, random_state = seed_value)\n",
    "    image_list_train, image_list_validation = train_test_split(image_list_train, test_size = val_ratio, random_state=seed_value)\n",
    "    train_cnt = val_cnt = test_cnt = 0\n",
    "    shutil.rmtree(PROCESSED_IMAGES_DIR, ignore_errors=True) # Deletes the directory containing any existing labeled images\n",
    "    shutil.rmtree(INDEX_DIR, ignore_errors=True)\n",
    "    for image_name in image_list:\n",
    "        label = getEncoding(image_name)\n",
    "        path = os.path.join(LABELED_IMAGES_DIR, image_name)\n",
    "        image = Image.open(path) # read in image\n",
    "        scaled_image_array = np.array(image)/255.\n",
    "        if label == -1: # if image unlabeled, move to next one\n",
    "            continue\n",
    "        if image_name in image_list_train:\n",
    "            data_train.append([scaled_image_array, label])\n",
    "            preprocessed_image_dict[image_name] = 'train-' + str(train_cnt)\n",
    "            train_cnt += 1\n",
    "        elif image_name in image_list_validation:\n",
    "            data_validation.append([scaled_image_array, label])\n",
    "            preprocessed_image_dict[image_name] = 'validation-' + str(val_cnt)\n",
    "            val_cnt += 1\n",
    "        else:\n",
    "            data_test.append([scaled_image_array, label])\n",
    "            preprocessed_image_dict[image_name] = 'test-' + str(test_cnt)\n",
    "            test_cnt += 1\n",
    "    if not os.path.exists(INDEX_DIR):\n",
    "        os.makedirs(INDEX_DIR)\n",
    "    with open(INDEX_LABELS, 'w', newline='') as f: # TODO: separate by tab not comma\n",
    "        writer = csv.DictWriter(f, fieldnames=csv_col_index)\n",
    "        writer.writeheader()\n",
    "        for key in preprocessed_image_dict.keys():\n",
    "            f.write(\"%s,%s\\n\"%(key,preprocessed_image_dict[key]))\n",
    "    filename_prefix = 'conflict-tiles'\n",
    "    data_filename_train = filename_prefix+ \"-train.npy\"\n",
    "    data_filename_test = filename_prefix + \"-test.npy\"\n",
    "    data_filename_validation = filename_prefix + \"-validation.npy\"\n",
    "    if not os.path.exists(PROCESSED_IMAGES_DIR): # check if 'tidy/preprocessed_images' subdirectory does not exist\n",
    "        os.makedirs(PROCESSED_IMAGES_DIR) # if not, create\n",
    "    if save_image_binary_files:\n",
    "        np.save(os.path.join(PROCESSED_IMAGES_DIR, data_filename_train), data_train) #save as .npy (binary) file\n",
    "        np.save(os.path.join(PROCESSED_IMAGES_DIR, data_filename_test), data_test) #save as .npy (binary) file    \n",
    "        np.save(os.path.join(PROCESSED_IMAGES_DIR, data_filename_validation), data_validation) #save as .npy (binary) file  \n",
    "        \n",
    "        print(\"Saved \" + data_filename_train + \" to \" + PROCESSED_IMAGES_DIR)\n",
    "        print(\"Saved \" + data_filename_test + \" to \" + PROCESSED_IMAGES_DIR)     \n",
    "        print(\"Saved \" + data_filename_validation + \" to \" + PROCESSED_IMAGES_DIR) \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fa206c2-e5fd-4cac-87b0-5283fcc5f885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 60%\n",
      " test set size: 20%\n",
      " validation set size: 20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nasko\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved conflict-tiles-train.npy to ../../data/tidy/preprocessed-images/\n",
      "Saved conflict-tiles-test.npy to ../../data/tidy/preprocessed-images/\n",
      "Saved conflict-tiles-validation.npy to ../../data/tidy/preprocessed-images/\n",
      "Time elapsed: 2min 41sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "processImageData()\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print('Time elapsed: {m}min {s}sec'.format(m=int(elapsed//60),s=int(np.round(elapsed%60,0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bae85c-7b55-4faa-b032-45fd16586e82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
